{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2cae3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cluster import KMeans, Birch, SpectralClustering, DBSCAN, MeanShift, estimate_bandwidth\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.manifold import MDS\n",
    "from math import floor\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c63931a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura de datos y funcion de normalizacion\n",
    "def norm_to_zero_one(df):\n",
    "    return (df - df.min()) * 1.0 / (df.max() - df.min())\n",
    "\n",
    "\n",
    "# Se pueden reemplazar los valores desconocidos por un número\n",
    "# datos = datos.replace(np.NaN,0)\n",
    "# O imputar, por ejemplo con la media\n",
    "def imputar_valores_perdidos(datos):\n",
    "    for col in datos:\n",
    "        if col != 'DB040':\n",
    "            datos[col].fillna(datos[col].mean(), inplace=True)\n",
    "            \n",
    "            \n",
    "# eliminar outliers como aquellos casos fuera de 1.5 veces el rango intercuartil\n",
    "def eliminar_outliers(X):\n",
    "    return X[(np.abs(stats.zscore(X)) < 3).all(axis=1)]\n",
    "\n",
    "\n",
    "def kmeans(X_normal, n_clusters_arg=5, n_init_arg=5, random_state_arg=123456):\n",
    "    print('----- Ejecutando k-Means',end='')\n",
    "    k_means = KMeans(init='k-means++', n_clusters=n_clusters_arg, n_init=n_init_arg, random_state=random_state_arg)\n",
    "    t = time.time()\n",
    "    cluster_predict = k_means.fit_predict(X_normal,subset['DB090']) #se usa DB090 como peso para cada objeto (factor de elevación)\n",
    "    tiempo = time.time() - t\n",
    "    print(\": {:.2f} segundos, \".format(tiempo), end='')\n",
    "    \n",
    "    return k_means, cluster_predict\n",
    "\n",
    "def birch(arg_branching_factor, arg_threshold, X_normal):\n",
    "    print('----- Ejecutando Birch, branching factor: ' + str(arg_branching_factor) + ', threshold: ' + str(arg_threshold), end='') # -----\n",
    "\n",
    "    #Tomamos tiempos\n",
    "    t = time.time()\n",
    "    # Ejecuto el algoritmo y asigno los clusters\n",
    "    birch = Birch(branching_factor=arg_branching_factor, threshold=arg_threshold, n_clusters=5)\n",
    "\n",
    "    cluster_predict = birch.fit_predict(X_normal)\n",
    "    tiempo = time.time() - t\n",
    "    #Pinto resultados\n",
    "    print(\": {:.2f} segundos, \".format(tiempo), end='')\n",
    "    \n",
    "    return birch, cluster_predict\n",
    "\n",
    "def spectralcluster(arg_n_cluster, X_normal):\n",
    "    #branching_factor = [15, 20, 25, 30, 35]\n",
    "    #threshold = [0.1, 0.15, 0.2, 0.25, 0.3]\n",
    "    print('----- Ejecutando spectralc luster', end='') # -----\n",
    "\n",
    "    #Tomamos tiempos\n",
    "    t = time.time()\n",
    "    # Ejecuto el algoritmo y asigno los clusters\n",
    "    spec = SpectralClustering(assign_labels='discretize', n_clusters=arg_n_cluster, random_state=123456)\n",
    "\n",
    "\n",
    "    cluster_predict = spec.fit_predict(X_normal)\n",
    "    tiempo = time.time() - t\n",
    "    #Pinto resultados\n",
    "    print(\": {:.2f} segundos, \".format(tiempo), end='')\n",
    "    \n",
    "    return spec, cluster_predict\n",
    "\n",
    "def alg_dbscan(arg_eps, arg_min_samples, X_normal):\n",
    "    #branching_factor = [15, 20, 25, 30, 35]\n",
    "    #threshold = [0.1, 0.15, 0.2, 0.25, 0.3]\n",
    "    print('----- Ejecutando spectralc luster', end='') # -----\n",
    "\n",
    "    #Tomamos tiempos\n",
    "    t = time.time()\n",
    "    # Ejecuto el algoritmo y asigno los clusters\n",
    "    dbscan = DBSCAN(eps=arg_eps, min_samples=arg_min_samples)\n",
    "\n",
    "\n",
    "    cluster_predict = dbscan.fit_predict(X_normal)\n",
    "    tiempo = time.time() - t\n",
    "    #Pinto resultados\n",
    "    print(\": {:.2f} segundos, \".format(tiempo), end='')\n",
    "    \n",
    "    return dbscan, cluster_predict\n",
    "\n",
    "def meanshift(arg_bandwidth, X_normal):\n",
    "    #branching_factor = [15, 20, 25, 30, 35]\n",
    "    #threshold = [0.1, 0.15, 0.2, 0.25, 0.3]\n",
    "    print('----- Ejecutando meanshift ', end='') # -----\n",
    "\n",
    "    #Tomamos tiempos\n",
    "    t = time.time()\n",
    "    # Ejecuto el algoritmo y asigno los clusters\n",
    "    mshift = MeanShift(bandwidth=arg_bandwidth)\n",
    "\n",
    "\n",
    "    cluster_predict = mshift.fit_predict(X_normal)\n",
    "    tiempo = time.time() - t\n",
    "    #Pinto resultados\n",
    "    print(\": {:.2f} segundos, \".format(tiempo), end='')\n",
    "    \n",
    "    return mshift, cluster_predict\n",
    "\n",
    "\n",
    "def metrica_CH(X_normal, cluster_predict):\n",
    "    metric_CH = metrics.calinski_harabasz_score(X_normal, cluster_predict)\n",
    "    print(\"Calinski-Harabasz Index: {:.3f}, \".format(metric_CH), end='')\n",
    "    return metric_CH\n",
    "\n",
    "\n",
    "# Esto es opcional, el cálculo de Silhouette puede consumir mucha RAM.\n",
    "# Si son muchos datos, digamos más de 10k, se puede seleccionar una muestra, p.ej., el 20%\n",
    "def metrica_SC(X_normal, cluster_predict):\n",
    "    muestra_silhoutte = 0.2 if (len(X) > 10000) else 1.0\n",
    "\n",
    "    metric_SC = metrics.silhouette_score(X_normal, cluster_predict, metric='euclidean', sample_size=floor(muestra_silhoutte*len(X)), random_state=123456)\n",
    "    print(\"Silhouette Coefficient: {:.5f}\".format(metric_SC))\n",
    "    return metric_SC\n",
    "\n",
    "\n",
    "def tamanio_clusters(clusters):\n",
    "    print(\"Tamaño de cada cluster:\")\n",
    "    size=clusters['cluster'].value_counts()\n",
    "    tams_clusters = []\n",
    "    for num,i in size.iteritems():\n",
    "       print('%s: %5d (%5.2f%%)' % (num,i,100*i/len(clusters)))\n",
    "       tams_clusters.append(i)\n",
    "    return tams_clusters, size\n",
    "\n",
    "\n",
    "def calcular_centros(algoritmo, X, k_means):\n",
    "    if algoritmo == 'kmeans' or algoritmo == 'meanshift':\n",
    "        centers = pd.DataFrame(k_means.cluster_centers_,columns=list(X))\n",
    "        centers_desnormal = centers.copy()\n",
    "\n",
    "        # se convierten los centros a los rangos originales antes de normalizar\n",
    "        for var in list(centers):\n",
    "            centers_desnormal[var] = X[var].min() + centers[var] * (X[var].max() - X[var].min())\n",
    "    elif algoritmo == 'birch':\n",
    "        centers = pd.DataFrame(k_means.subcluster_centers_,columns=list(X))\n",
    "        centers_desnormal = centers.copy()\n",
    "\n",
    "        # se convierten los centros a los rangos originales antes de normalizar\n",
    "        for var in list(centers):\n",
    "            centers_desnormal[var] = X[var].min() + centers[var] * (X[var].max() - X[var].min())\n",
    "    else:\n",
    "        centers = None\n",
    "        centers_desnormal = None\n",
    "    return centers, centers_desnormal\n",
    "\n",
    "\n",
    "# heatmap\n",
    "def heatmap(centers, centers_desnormal, size):\n",
    "    print(\"---------- Heatmap...\")\n",
    "    centers.index += 1\n",
    "    hm = sns.heatmap(centers, cmap=\"YlGnBu\", annot=centers_desnormal, annot_kws={\"fontsize\":18}, fmt='.3f')\n",
    "    hm.set_ylim(len(centers),0)\n",
    "    hm.figure.set_size_inches(15,15)\n",
    "    #hm.figure.savefig(\"centroides.png\")\n",
    "    centers.index -= 1\n",
    "\n",
    "    k = len(size)\n",
    "    colors = sns.color_palette(palette='Paired', n_colors=k, desat=None)\n",
    "    \n",
    "\n",
    "# Scatter matrix\n",
    "def scatter_matrix(X, clusters, size):\n",
    "    print(\"---------- Scatter matrix...\")\n",
    "    # se añade la asignación de clusters como columna a X\n",
    "    X_kmeans = pd.concat([X, clusters], axis=1)\n",
    "    k = len(size)\n",
    "    colors = sns.color_palette(palette='Paired', n_colors=k, desat=None)\n",
    "    #'''\n",
    "    sns.set()\n",
    "    variables = list(X_kmeans)\n",
    "    variables.remove('cluster')\n",
    "    sns_plot = sns.pairplot(X_kmeans, vars=variables, hue=\"cluster\", palette=colors, plot_kws={\"s\": 25}, diag_kind=\"hist\") #en hue indicamos que la columna 'cluster' define los colores\n",
    "    sns_plot.fig.subplots_adjust(wspace=.03, hspace=.03)\n",
    "    sns_plot.fig.set_size_inches(15,15)\n",
    "    #sns_plot.savefig(\"scatter.png\")\n",
    "    #'''\n",
    "    \n",
    "    \n",
    "# Boxplot\n",
    "def boxplot(size, centers):\n",
    "    print(\"---------- Boxplots...\")\n",
    "    \n",
    "    X_kmeans = pd.concat([X, clusters], axis=1)\n",
    "    k = len(size)\n",
    "    colors = sns.color_palette(palette='Paired', n_colors=k, desat=None)\n",
    "    \n",
    "    fig, axes = plt.subplots(k, n_var, sharey=True,figsize=(15,15))\n",
    "    fig.subplots_adjust(wspace=0,hspace=0)\n",
    "\n",
    "    centers_sort = centers.sort_values(by=['renta']) #ordenamos por renta para el plot\n",
    "\n",
    "    rango = []\n",
    "    for j in range(n_var):\n",
    "       rango.append([X_kmeans[usadas[j]].min(),X_kmeans[usadas[j]].max()])\n",
    "\n",
    "    for i in range(k):\n",
    "        c = centers_sort.index[i]\n",
    "        dat_filt = X_kmeans.loc[X_kmeans['cluster']==c]\n",
    "        for j in range(n_var):\n",
    "            # Esto sale mal si quito el comentario y comento lo sigueinte al profe le sale mal y nos abe por que xd\n",
    "            #ax = sns.kdeplot(x=dat_filt[usadas[j]], label=\"\", shade=True, color=colors[c], ax=axes[i,j])\n",
    "            ax = sns.boxplot(x=dat_filt[usadas[j]], notch=True, color=colors[c], flierprops={'marker':'o','markersize':4}, ax=axes[i,j])\n",
    "\n",
    "            if (i==k-1):\n",
    "                axes[i,j].set_xlabel(usadas[j])\n",
    "            else:\n",
    "                axes[i,j].set_xlabel(\"\")\n",
    "\n",
    "            if (j==0):\n",
    "               axes[i,j].set_ylabel(\"Cluster \"+str(c+1))\n",
    "            else:\n",
    "                axes[i,j].set_ylabel(\"\")\n",
    "\n",
    "            axes[i,j].set_yticks([])\n",
    "            axes[i,j].grid(axis='x', linestyle='-', linewidth='0.2', color='gray')\n",
    "            axes[i,j].grid(axis='y', b=False)\n",
    "\n",
    "            ax.set_xlim(rango[j][0]-0.05*(rango[j][1]-rango[j][0]),rango[j][1]+0.05*(rango[j][1]-rango[j][0]))\n",
    "\n",
    "    fig.set_size_inches(15,15)\n",
    "    #fig.savefig(\"boxplots.png\")\n",
    "    \n",
    "\n",
    "# MDS\n",
    "def graf_MDS(centers, size):\n",
    "    print(\"---------- MDS...\")\n",
    "    X_kmeans = pd.concat([X, clusters], axis=1)\n",
    "    k = len(size)\n",
    "    colors = sns.color_palette(palette='Paired', n_colors=k, desat=None)\n",
    "    \n",
    "    mds = MDS(random_state=123456)\n",
    "    centers_mds = mds.fit_transform(centers)\n",
    "    fig=plt.figure(4)\n",
    "    \n",
    "    plt.scatter(centers_mds[:,0], centers_mds[:,1], s=size*10, alpha=0.75, c=colors)\n",
    "    for i in range(k):\n",
    "        plt.annotate(str(i+1),xy=centers_mds[i],fontsize=18,va='center',ha='center')\n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.yticks(fontsize=18)\n",
    "    fig.set_size_inches(15,15)\n",
    "    #plt.savefig(\"mds.png\")\n",
    "    \n",
    "def sacar_graficas(algoritmo, centers, centers_desnormal, size, X, clusters):\n",
    "    if algoritmo == 'kmeans':\n",
    "        heatmap(centers, centers_desnormal, size)\n",
    "        scatter_matrix(X, clusters, size)\n",
    "        boxplot(size, centers)\n",
    "        graf_MDS(centers, size)\n",
    "    else:\n",
    "        scatter_matrix(X, clusters, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20a85aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Ejecutando k-Means: 0.75 segundos, \n",
      "\n",
      "Medidas\n",
      "\n",
      "\n",
      "Calinski-Harabasz Index: 935.836, Silhouette Coefficient: 0.21971\n",
      "----- Ejecutando Birch, branching factor: 15, threshold: 0.1: 0.25 segundos, \n",
      "\n",
      "Medidas\n",
      "\n",
      "\n",
      "Calinski-Harabasz Index: 528.359, Silhouette Coefficient: 0.14048\n",
      "----- Ejecutando spectralc luster: 2.37 segundos, \n",
      "\n",
      "Medidas\n",
      "\n",
      "\n",
      "Calinski-Harabasz Index: 830.399, Silhouette Coefficient: 0.21667\n",
      "----- Ejecutando spectralc luster: 0.07 segundos, \n",
      "\n",
      "Medidas\n",
      "\n",
      "\n",
      "Calinski-Harabasz Index: 515.594, Silhouette Coefficient: 0.32974\n",
      "----- Ejecutando meanshift : 17.88 segundos, \n",
      "\n",
      "Medidas\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "De medidas nada\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datos = pd.read_csv('datos_hogar_2020.csv')\n",
    "\n",
    "imputar_valores_perdidos(datos)\n",
    "\n",
    "# Seleccionar casos\n",
    "subset = datos.loc[(datos['HY030N']>0) & (datos['HC030_F']==1)] #solo los que se conoce el alquiler imputado y gasto en transporte público\n",
    "\n",
    "# Seleccionar variables de interés para clustering\n",
    "# renombramos las variables por comodidad\n",
    "subset=subset.rename(columns={\"HY020\": \"renta\", \"HY030N\": \"alquiler_imputado\", \"HC010\": \"alimentacion_in\", \"HC030\": \"transporte\"})\n",
    "usadas = ['renta','alquiler_imputado','alimentacion_in','transporte']\n",
    "\n",
    "n_var = len(usadas)\n",
    "X = subset[usadas]\n",
    "n_var = len(usadas)\n",
    "X = subset[usadas]\n",
    "\n",
    "algoritmos = ['kmeans', 'birch', 'spectral', 'dbscan', 'meanshift']\n",
    "\n",
    "X = eliminar_outliers(X)\n",
    "    \n",
    "# normalizamos\n",
    "X_normal = X.apply(norm_to_zero_one)\n",
    "\n",
    "for i in range(0, len(algoritmos)):\n",
    "    if algoritmos[i] == 'kmeans':\n",
    "        res, cluster_predict = kmeans(X_normal)\n",
    "    elif algoritmos[i] == 'birch':\n",
    "        res, cluster_predict = birch(15, 0.1, X_normal)\n",
    "    elif algoritmos[i] == 'spectral':\n",
    "        res, cluster_predict = spectralcluster(5, X_normal)\n",
    "    elif algoritmos[i] == 'dbscan':\n",
    "        res, cluster_predict = alg_dbscan(0.126, 20, X_normal)\n",
    "    elif algoritmos[i] == 'meanshift':\n",
    "        bw = estimate_bandwidth(X_normal)\n",
    "        res, cluster_predict = meanshift(bw, X_normal)\n",
    "    \n",
    "    try:\n",
    "        print(\"\\n\\nMedidas\\n\\n\")\n",
    "        metrica_CH(X_normal, cluster_predict)\n",
    "\n",
    "        metrica_SC(X_normal, cluster_predict)\n",
    "    except:\n",
    "        print(\"\\n\\nDe medidas nada\\n\\n\")\n",
    "    \n",
    "    # se convierte la asignación de clusters a DataFrame\n",
    "    clusters = pd.DataFrame(cluster_predict,index=X.index,columns=['cluster'])\n",
    "\n",
    "    #tam_clusters, size = tamanio_clusters(clusters)\n",
    "\n",
    "    centers, centers_desnormal = calcular_centros(algoritmos[i], X, res)\n",
    "\n",
    "    #sacar_graficas(algoritmos[i], centers, centers_desnormal, size, X, clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c071fa41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

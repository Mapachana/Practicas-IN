%\ctparttext{\color{black}\begin{center}
%		Esta es una descripción de la parte de informática.
%\end{center}}

%\part{Parte de informática}
\chapter{Caso 2: Comparación de rentas}


\section{Descripción del caso de estudio}
Este caso de estudio trata de contrastar las diferencias que hay entre grupos con renta baja (menor de $15000$€ al año) y renta alta (mayor de $25000$€ al año).

Para ello, las variables seleccionadas son:
\begin{itemize}
\item \textbf{Renta}: Renta disponible total del hogar en el año anterior al de encuesta.
\item \textbf{Alimentos}: Durante el mes pasado, ¿cuál fue aproximadamente el importe que el hogar gastó en alimentos y bebidas no alcohólicas para ser consumidas en casa?
\item \textbf{Asistencia social}: Ingresos por asistencia social en el año anterior al
de encuesta.
\item \textbf{Gastos}: Gastos de la vivienda: Alquiler (si la vivienda se encuentra en régimen de alquiler), intereses de la hipoteca (para viviendas en propiedad con pagos pendientes) y otros gastos asociados (comunidad, agua, electricidad, gas, etc.)
\end{itemize}

Para realizar la comparativa, vamos a estudiar dos subcasos, el primero con renta baja y el segundo con renta alta.

\section{Caso 2 A: Renta baja}

Este caso de estudio consta de $3197$ elementos, cada uno con las cuatro variables especificadas antes.

\subsection{Ejecución de algoritmos}

Ejecutamos la celda del notebook de jupyter correspondiente al caso 2A (que se puede configurar para sacar las distintas gráficas) y obtenemos así las diferentes medidas obtenidas para cada algoritmo, que se muestran en \eqref{tab:c2A_alg}.

\begin{table}[H]
\centering
\caption{Caso 2A - Resultados de ejecución de algoritmos.}
\label{tab:c2A_alg}
\begin{tabular}{ccccc}
\toprule
 Algoritmo & Tiempo (s) & Calinski-Harabasz & Silhouette & Número de clusters \\
\midrule
kmeans & 0.385 & 1157.588 & 0.31325 & 5 \\
birch & 0.124 & 510.565 & 0.26449 & 5 \\
spectral & 1.739 & 1068.474 & 0.30286 & 5 \\
dbscan & 0.171 & 304.282 & 0.60850 & 2 \\
meanshift & 18.233 & 184.067 & 0.40807 & 11 \\
\bottomrule
\end{tabular}
\end{table}

Respecto a los tiempos, de nuevo el algoritmo más lento es meanshift, seguido de spectral cluster. El resto de algoritmos obtienen tiempo similares.

Además, al igual que en el caso 1 DBSCAN ha generado solamente dos clusters, uno con el $97.12\%$ de los datos y los restantes en el cluster -1. Meanshift vuelve a generar más cluster que el resto, agrupando uno de ellos al $91.46\%$ de elementos, otro al $4.86\%$ y el resto cada uno contiene un número de elementos menor al $1.2\%$ del total. Por ello, parece que a pesar de las medidas que han obtenido, estos algoritmos no han realizado un buen agrupamiento.

Finalmente vemos como Birch tiene un valor de Calinski-Harabasz y silhouette más bajo que kmeans y spectral cluster. Estos algoritmos han conseguido medidas similares, obteniendo en principio kmeans mejores resultados.


\subsection{Análisis}


Para el análisis se va a usar kmeans, ya que ha obtenido las mejores medidas. Este algoritmo genera 5 clusters. Se ha generado un cluster de tamaño menor, y los otros tienen tamaños similares dos a dos, como se puede ver en \eqref{c2A_tam}.

\begin{figure}[H]
\caption{Caso 2A- Tamaño de los clusters generados por kmeans}
\label{c2A_tam}
\includegraphics[scale=1]{caso2A/kmeans/bar.eps}
\end{figure}

A continuación observamos la scatter matrix \eqref{c2A_scatter}, donde se puede apreciar como se separan los clusters y qué variables son necesarias para diferenciar cada uno. Hay varios clusters que se diferencian bien con una sola variable, como es el caso de cluster 0, que tiene valores altos de gastos, el 4 tiene valores más altos en asistencia social y el 2 gasta más en alimentación. Los clusters 1 y 3 se distinguen bien usando renta y gastos o renta y alimentos, ya que ambos tienen valores bajos de renta y uno tiene valores mayores que el otro en la variable restante.

\begin{figure}[H]
\caption{Caso 2A- Scatter matrix de kmeans}
\label{c2A_scatter}
\includegraphics[scale=0.45]{caso2A/kmeans/scatter.png}
\end{figure}


\begin{figure}[H]
\caption{Caso 2A- Heatmap de kmeans}
\label{c2A_heatmap}
\includegraphics[scale=0.45]{caso2A/kmeans/heatmap.png}
\end{figure}

En \eqref{c2A_heatmap} se ve con claridad los tres clusters que se diferencian por tomar valores especialmente altos en una de sus variables. Teniendo en cuenta que la numeración en este gráfico va de 1 a 5 y en la scatter matrix va de 0 a 4, vemos la analogía. En el heatmap se aprecia como el cluster 5 toma valores considerablemente más altos en asistencia social que el resto de clusters, el 3 toma valores más altos en alimentación y el 1 en gastos, lo que concuerda con lo visto en la scatter matrix.


\begin{figure}[H]
\caption{Caso 2A- MDS de kmeans}
\label{c2A_mds}
\includegraphics[scale=0.45]{caso2A/kmeans/mds.png}
\end{figure}

En \eqref{c2A_mds} se observa como los clusters están separados entre sí y tienen tamaños similares salvo por el cluster 5, que es de menor tamaño, como ya vimos al analizar los tamaños antes.

\begin{figure}[H]
\caption{Caso 2A - Parallel coordinates de kmeans}
\label{c2A_parallel}
\includegraphics[scale=0.4]{caso2A/kmeans/parallel.png}
\end{figure}

En \eqref{c2A_parallel} se aprecia como el cluster rosa, que alcanza mayores valores de asistencia social, es más disperso que los demás, lo que concuerda con la scatter matrix \eqref{c2A_scatter}. De nuevo, es claro que hay dos clusters que se diferencian por sus valores altos en alimentación y gastos.

En la tabla  \eqref{tab:c2A_variables} se muestran qué variables son necesarias para identificar cada cluster:

\begin{table}[H]
\centering
\caption{Caso 2A - Variables necesarias para separar el clustering en spectral cluster}
\label{tab:c2A_variables}
\begin{tabular}{ccccc}
\toprule
 Cluster & renta & alimentos & asistencia social & gastos \\
\midrule
0 & & & & Altos \\
1 & Baja & Bajos & & Bajos \\
2 & & Altos & & \\
3 & Alta & Bajos & & Bajos \\
4 & & & Altos & \\
\bottomrule
\end{tabular}
\end{table}
Como se aprecia en \eqref{tab:c2A_variables} con una sola variable en cada cluster nos sirve para diferenciarlos entre los clusters 0, 2 y 4, mientras para los clusters 1 y 3 necesitamos dos para diferenciarlos entre ellos.

\subsection{Estudio de parámetros de DBSCAN}

Vamos a analizar el comportamiento de DBSCAN según sus parámetros principales. Para ello ejecutaremos la celda de parámetros de DBSCAN, que nos proporciona las medidas obtenidas para cada par de parámetros.

\begin{table}[H]
\centering
\caption{Caso 2A - Cambio de parámetros DBSCAN}
\label{tab:c2A_dbscan}
\begin{tabular}{ccccccc}
\toprule
Algoritmo & eps & min samples & Tiempo(s) & Calinski-Harabasz & Silhouette & n clusters \\
\midrule
dbscan & 0.126 & 15 & 0.210 & 283.280 & 0.62692 & 2 \\
dbscan & 0.126 & 20 & 0.177 & 304.282 & 0.60850 & 2 \\
dbscan & 0.126 & 25 & 0.185 & 343.349 & 0.59182 & 2 \\
dbscan & 0.126 & 30 & 0.181 & 357.820 & 0.58212 & 2 \\
dbscan & 0.126 & 35 & 0.188 & 361.064 & 0.57576 & 2 \\
dbscan & 0.130 & 15 & 0.190 & 223.006 & 0.63128 & 2 \\
dbscan & 0.130 & 20 & 0.194 & 279.313 & 0.62217 & 2 \\
dbscan & 0.130 & 25 & 0.184 & 324.483 & 0.60954 & 2 \\
dbscan & 0.130 & 30 & 0.193 & 345.157 & 0.60186 & 2 \\
dbscan & 0.130 & 35 & 0.193 & 354.160 & 0.58156 & 2 \\
dbscan & 0.150 & 15 & 0.247 & 133.391 & 0.67010 & 2 \\
dbscan & 0.150 & 20 & 0.212 & 208.220 & 0.65089 & 2 \\
dbscan & 0.150 & 25 & 0.213 & 234.186 & 0.64523 & 2 \\
dbscan & 0.150 & 30 & 0.219 & 244.053 & 0.63871 & 2 \\
dbscan & 0.150 & 35 & 0.232 & 277.293 & 0.63108 & 2 \\
dbscan & 0.170 & 15 & 0.245 & 106.562 & 0.68737 & 2 \\
dbscan & 0.170 & 20 & 0.243 & 112.836 & 0.68127 & 2 \\
dbscan & 0.170 & 25 & 0.241 & 154.421 & 0.66746 & 2 \\
dbscan & 0.170 & 30 & 0.231 & 179.415 & 0.66353 & 2 \\
dbscan & 0.170 & 35 & 0.479 & 197.375 & 0.66118 & 2 \\
dbscan & 0.200 & 15 & 0.283 & 77.501 & 0.69224 & 2 \\
dbscan & 0.200 & 20 & 0.256 & 95.258 & 0.68918 & 2 \\
dbscan & 0.200 & 25 & 0.254 & 103.127 & 0.68949 & 2 \\
dbscan & 0.200 & 30 & 0.252 & 107.818 & 0.68620 & 2 \\
dbscan & 0.200 & 35 & 0.239 & 110.824 & 0.68431 & 2 \\
\bottomrule
\end{tabular}
\end{table}

Como podemos apreciar en \eqref{tab:c2A_dbscan} DBSCAN siempre realiza dos clusters. El tamaño de estos es siempre similar, más del $90\%$ los ejemplos están agrupados en el cluster $0$ y los restantes están en el $-1$.

Nuevamente este algoritmo no ha hecho ninguna buena agrupación en ningún caso de los probados, pese a que su silhouette es bastante alto, lo que puede ser consecuencia de que los clusters estén muy separados.

\begin{figure}[H]
\caption{Caso 2A- Parámetros de DBSCAN}
\label{c2A_param_dbscan}
\includegraphics[scale=0.9]{caso2A/A_parametros_dbscan.eps}
\end{figure}

Respecto a los valores obtenidos de Calinski-Harabasz se puede ver en \eqref{c2A_param_dbscan} como, de nuevo, a mayor valor de silhouette menor de Calinski-harabasz, donde este es decreciente y el silhouette creciente. Si quisiéramos maximizar silhouette, tomaríamos min samples como 15 y el mayor valor de epsilon, mientras para maximizar Calinski-Harabasz es mejor el valor 35 de min samples con el menor valor de epsilon.


\subsection{Estudio de parámetros de Kmeans}

Estudiamos ahora el algoritmo Kmeans. Como parámetro se ha variado el número de clusters.

\begin{table}[H]
\centering
\caption{Caso 2A - Cambio de parámetros Kmeans}
\label{tab:c2A_kmeans}
\begin{tabular}{cccccc}
\toprule
Algoritmo & n clusters & Tiempo(s) & Calinski-Harabasz & Silhouette & n clusters \\
\midrule
kmeans & 3 & 0.224 & 960.927 & 0.28417 & 3 \\
kmeans & 4 & 0.122 & 1162.049 & 0.31899 & 4 \\
kmeans & 5 & 0.283 & 1157.588 & 0.31325 & 5 \\
kmeans & 6 & 0.292 & 1174.483 & 0.32302 & 6 \\
kmeans & 7 & 0.328 & 1107.187 & 0.31675 & 7 \\
kmeans & 8 & 0.183 & 1074.974 & 0.31710 & 8 \\
kmeans & 9 & 0.487 & 1031.378 & 0.31904 & 9 \\
kmeans & 10 & 1.043 & 992.485 & 0.29012 & 10 \\
\bottomrule
\end{tabular}
\end{table}

Podemos ver en \eqref{tab:c2A_kmeans} que no hay demasiada diferencia entre las medidas obtenidas para los distintos valores del número de clusters.

\begin{figure}[H]
\caption{Caso 2A- Parámetros de Kmeans}
\label{c2A_param_kmeans}
\includegraphics[scale=0.9]{caso2A/A_parametros_kmeans.eps}
\end{figure}

En \eqref{c2A_param_kmeans} destaca que el valor para el que se alcanza el máximo en Silhouette es el mismo para el que se alcanza el máximo en Calinski-harabasz, que es 6 clusters. Por tanto, este parece el mejor agrupamiento a realizar.

Aún así, kmeans ha dado resultados buenos en todos los casos y ha demostrado ser bastante robusto en sus agrupaciones.



\section{Caso 2 B: Renta alta}

Este caso de estudio consta de $8372$ elementos, cada uno con las cuatro variables especificadas antes.

\subsection{Ejecución de algoritmos}

Ejecutamos la celda del notebook de jupyter correspondiente al caso 2B y obtenemos las diferentes medidas obtenidas para cada algoritmo, que se muestran en \eqref{tab:c2B_alg}.

\begin{table}[H]
\centering
\caption{Caso 2B - Resultados de ejecución de algoritmos.}
\label{tab:c2B_alg}
\begin{tabular}{ccccc}
\toprule
 Algoritmo & Tiempo (s) & Calinski-Harabasz & Silhouette & Número de clusters \\
\midrule
kmeans & 0.531 & 2962.319 & 0.30911 & 5 \\
birch & 0.312 & 645.084 & 0.47807 & 5 \\
spectral & 20.642 & 2145.100 & 0.32184 & 5 \\
dbscan & 1.532 & 473.629 & 0.75774 & 2 \\
meanshift & 68.273 & 211.786 & 0.40726 & 31 \\
\bottomrule
\end{tabular}
\end{table}

Respecto a los tiempos, de nuevo el algoritmo más lento es meanshift, seguido de spectral cluster. El resto de algoritmos obtienen tiempo similares. Cabe destacar que al incrementarse el número de instancias los tiempo han subido considerablemente, en especial el de meanshift, ya que calcular bandwith es costoso.

Además, al igual que en los casos anteriores DBSCAN ha generado solamente dos clusters, uno con el $99.44\%$ de los datos y los restantes en el cluster -1. Meanshift vuelve a generar más cluster que el resto, agrupando uno de ellos el $93.37\%$ de elementos, y el resto son  agrupaciones de menos el $2\%$ de elementos. Por ello, parece que a pesar de las medidas que han obtenido, estos algoritmos no han realizado un buen agrupamiento.

Finalmente vemos como Birch tiene un valor de Calinski-Harabasz más bajo que kmeans y spectral cluster, aunque obtiene un silhouette mayor.

\subsection{Análisis}


Para el análisis se va a usar kmeans, como se hizo en el caso anterior para poder realizar la comparación. Este algoritmo genera 5 clusters. Se ha generado un cluster grande con algo más de la mitad de los datos, uno mediano y el resto pequeños, como se puede ver en \eqref{c2B_tam}.

\begin{figure}[H]
\caption{Caso 2B- Tamaño de los clusters generados por kmeans}
\label{c2B_tam}
\includegraphics[scale=1]{caso2B/kmeans/bar.eps}
\end{figure}

A continuación observamos la scatter matrix \eqref{c2B_scatter}, donde se puede apreciar como se separan os clusters y qué variables son necesarias para separar cada uno. De manera análoga al caso 2A vemos como se pueden separar varios clusters solamente por valores altos de ciertas variables, que son el cluster 1 con grandes gastos, el 2 con alimentos y el 3 por valores muy altos de renta. Los clusters 0 y 4 requieren de varias variables para distinguirse, que son alimentos y gastos.

\begin{figure}[H]
\caption{Caso 2B- Scatter matrix de kmeans}
\label{c2B_scatter}
\includegraphics[scale=0.45]{caso2B/kmeans/scatter.png}
\end{figure}


\begin{figure}[H]
\caption{Caso 2B- Heatmap de kmeans}
\label{c2B_heatmap}
\includegraphics[scale=0.45]{caso2B/kmeans/heatmap.png}
\end{figure}

En \eqref{c2B_heatmap} se ve con claridad los tres clusters que se diferencian por tomar valores especialmente altos en una de sus variables. Teniendo en cuenta que la numeración en este gráfico va de 1 a 5 y en la scatter matrix va de 0 a 4, vemos la analogía. En el heatmap se distingue como el cluster 2 toma valores considerablemente más altos en gastos que el resto de clusters, el 3 toma valores más altos en alimentación y el 4 en renta, lo que concuerda con lo visto en la scatter matrix.


\begin{figure}[H]
\caption{Caso 2B- MDS de kmeans}
\label{c2B_mds}
\includegraphics[scale=0.45]{caso2B/kmeans/mds.png}
\end{figure}

En \eqref{c2B_mds} se aprecia como los clusters están separados entre sí y hay un cluster más grande, otro medio y tres más pequeños.

\begin{figure}[H]
\caption{Caso 2B - Parallel coordinates de kmeans}
\label{c2B_parallel}
\includegraphics[scale=0.4]{caso2B/kmeans/parallel.png}
\end{figure}

En \eqref{c2B_parallel} se observa como el cluster verde claro  alcanza mayores valores de alimentos, como veíamos en las gráficas anteriores. De nuevo, es claro que hay dos clusters que se diferencian por sus valores altos en alimentación y gastos.

También resalta mucho en \eqref{c2B_heatmap} y \eqref{c2B_parallel} como la asistencia social, en general, es 0 salvo para algunos objetos.

En la tabla  \eqref{tab:c2B_variables} se muestran qué variables son necesarias para identificar cada cluster:

\begin{table}[H]
\centering
\caption{Caso 2B - Variables necesarias para separar el clustering en spectral cluster}
\label{tab:c2B_variables}
\begin{tabular}{ccccc}
\toprule
 Cluster & renta & alimentos & asistencia social & gastos \\
\midrule
0 & & Bajos & & Bajos \\
1 & & & & Altos \\
2 & & Altos & & \\
3 & Alta & & & \\
4 & & Medios & & Bajos \\
\bottomrule
\end{tabular}
\end{table}
Como se aprecia en \eqref{tab:c2B_variables} con una sola variable en cada cluster nos sirve para diferenciarlos entre los clusters 1, 2 y 3, mientras para los clusters 0 y 4 necesitamos dos para diferenciarlos entre ellos.

\subsection{Estudio de parámetros de DBSCAN}

Vamos a analizar el comportamiento de DBSCAN según sus parámetros principales. Para ello ejecutaremos la celda de parámetros de DBSCAN, que nos proporciona las medidas obtenidas para los parámetros dados.

\begin{table}[H]
\centering
\caption{Caso 2B - Cambio de parámetros DBSCAN}
\label{tab:c2B_dbscan}
\begin{tabular}{ccccccc}
\toprule
Algoritmo & eps & min samples & Tiempo(s) & Calinski-Harabasz & Silhouette & n clusters \\
\midrule
dbscan & 0.126 & 15 & 2.367 & 468.250 & 0.76037 & 2 \\
dbscan & 0.126 & 20 & 1.638 & 473.629 & 0.75774 & 2 \\
dbscan & 0.126 & 25 & 1.662 & 509.168 & 0.75308 & 2 \\
dbscan & 0.126 & 30 & 1.580 & 520.993 & 0.75022 & 2 \\
dbscan & 0.126 & 35 & 1.564 & 557.247 & 0.74668 & 2 \\
dbscan & 0.130 & 15 & 1.676 & 444.386 & 0.76270 & 2 \\
dbscan & 0.130 & 20 & 1.624 & 473.629 & 0.75774 & 2 \\
dbscan & 0.130 & 25 & 1.622 & 473.629 & 0.75774 & 2 \\
dbscan & 0.130 & 30 & 1.557 & 502.252 & 0.75391 & 2 \\
dbscan & 0.130 & 35 & 1.516 & 543.389 & 0.74931 & 2 \\
dbscan & 0.150 & 15 & 1.775 & 364.846 & 0.78084 & 2 \\
dbscan & 0.150 & 20 & 1.693 & 401.486 & 0.77691 & 2 \\
dbscan & 0.150 & 25 & 1.640 & 401.486 & 0.77691 & 2 \\
dbscan & 0.150 & 30 & 1.701 & 419.823 & 0.77129 & 2 \\
dbscan & 0.150 & 35 & 1.676 & 431.335 & 0.77072 & 2 \\
dbscan & 0.170 & 15 & 1.725 & 326.815 & 0.78982 & 2 \\
dbscan & 0.170 & 20 & 1.751 & 326.815 & 0.78982 & 2 \\
dbscan & 0.170 & 25 & 1.852 & 343.916 & 0.78744 & 2 \\
dbscan & 0.170 & 30 & 1.673 & 343.916 & 0.78744 & 2 \\
dbscan & 0.170 & 35 & 1.713 & 343.916 & 0.78744 & 2 \\
dbscan & 0.200 & 15 & 1.743 & 234.734 & 0.81097 & 2 \\
dbscan & 0.200 & 20 & 1.728 & 236.469 & 0.80628 & 2 \\
dbscan & 0.200 & 25 & 1.601 & 274.152 & 0.80115 & 2 \\
dbscan & 0.200 & 30 & 1.732 & 277.749 & 0.79948 & 2 \\
dbscan & 0.200 & 35 & 1.686 & 309.161 & 0.79346 & 2 \\
\bottomrule
\end{tabular}
\end{table}

Como podemos apreciar en \eqref{tab:c2B_dbscan} DBSCAN siempre realiza dos clusters. El tamaño de estos es siempre similar, más del $90\%$ los ejemplos están agrupados en el cluster $0$ y los restantes están en el $-1$.

Este algoritmo no ha hecho ninguna buena agrupación en ningún caso de los probados, pese a que, de nuevo su silhouette es bastante alto.

\begin{figure}[H]
\caption{Caso 2B- Parámetros de DBSCAN}
\label{c2B_param_dbscan}
\includegraphics[scale=0.9]{caso2B/B_parametros_dbscan.eps}
\end{figure}


En \eqref{c2B_param_dbscan} se aprecia que no hay demasiada diferencia entre las medidas al variar los parámetros, aunque Calinski-harabasz es decendiente y silhouette creciente. No hay un punto donde ambos alcancen el  máximo, y se debería realizar un estudio más a fondo o probar para los valores.

Igualmente, al generar solamente dos clusters, como ya se ha mencionado, la agrupación no parece ser buena.


\subsection{Estudio de parámetros de Kmeans}

Estudiamos ahora el algoritmo Kmeans. Se ha variado el número de clusters.

\begin{table}[H]
\centering
\caption{Caso 2B - Cambio de parámetros Kmeans}
\label{tab:c2B_kmeans}
\begin{tabular}{cccccc}
\toprule
Algoritmo & n clusters & Tiempo(s) & Calinski-Harabasz & Silhouette & n clusters \\
\midrule
kmeans & 3 & 0.392 & 3085.841 & 0.39834 & 3 \\
kmeans & 4 & 0.243 & 3065.400 & 0.40218 & 4 \\
kmeans & 5 & 0.407 & 2962.319 & 0.30911 & 5 \\
kmeans & 6 & 0.441 & 2878.260 & 0.31752 & 6 \\
kmeans & 7 & 0.496 & 2799.096 & 0.31771 & 7 \\
kmeans & 8 & 0.508 & 2760.228 & 0.27617 & 8 \\
kmeans & 9 & 0.787 & 2707.579 & 0.27781 & 9 \\
kmeans & 10 & 0.891 & 2620.283 & 0.27880 & 10 \\
\bottomrule
\end{tabular}
\end{table}

Podemos ver en \eqref{tab:c2B_kmeans} como las medidas comienzan subiendo hasta que el número de clusters es 4, donde alcanzan su máximo Silhouette y el segundo mayor valor de Calinski-harabasz, para después volver comenzar a decrementarse.

Asimismo el tiempo de ejecución se incrementa a la par que el número de clusters crece, pues hay que hacer más cálculos.

\begin{figure}[H]
\caption{Caso 2B- Parámetros de Kmeans}
\label{c2B_param_kmeans}
\includegraphics[scale=0.9]{caso2B/B_parametros_kmeans.eps}
\end{figure}

Estudiamos ahora \eqref{c2B_param_kmeans}, en la que se puede ver como el silhouette no varía monótonamente. Calinski-Harabasz sí es monótonamente decreciente.

Al contrario que en el subcaso anterior, no hay un valor del número de clusters que maximice ambas medidas, aunque el punto en el que se alcanza el mayor silhouette, con 4 clusters, tiene también el segundo valor más alto de Calinski-harabasz.

A la vista de estas medidas, y a la falta de realizar un estudio mucho más en profundidad, parece que la mejor agrupación sería con 4 clusters.


\section{Interpretación de la segmentación}

Una variable bastante relevante al comparar estos casos ha sido la asistencia social, ya que en el caso de rentas altas la mayor parte de objetos no recibían (valía 0), mientras para rentas bajas ha sido muy relevante a la hora de realizar agrupamientos, incluso siendo suficiente como para diferenciar un cluster si su valor era alto en las rentas bajas.

En ambos casos los gastos y alimentación han servido para separar dos clusters del resto usando solamente una de ellas. Si comparamos ambas, usando por ejemplos \eqref{c2A_scatter} y \eqref{c2B_scatter} vemos que en el caso de alimentación para rentas altas se considera un valor alto de esta variable a partir de $1000$, mientras para rentas bajas es $400$. Igualmente, para gastos en rentas altas el valor de corte es en torno a $500$, pero para rentas bajas se considera más o menos $350$.

Además, vemos como en general los valores de gastos y alimentación son considerablemente más altos para rentas altas que para rentas bajas.

Para separar los otros clusters usamos dos variables, donde una de ellas es la renta, por lo tanto es de menos utilidad al compararlos, ya que la renta está sesgada en cada caso de estudio.

Así, vemos como las personas con rentas más altas prácticamente no tienen ayudas sociales y gastan más en alimentos y gastos de alquiler y similares, mientras las personas con rentas bajas cuentan con más ayudas sociales y gastan menos en alimentación y gastos del hogar.




